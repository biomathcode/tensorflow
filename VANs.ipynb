{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VANs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratiksharm/tensorflow/blob/master/VANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coE1tt9vHBrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f808bff2-9ac8-431c-db12-3b6e6e2c2d8f"
      },
      "source": [
        "!pip install imageio\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.16.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdAsjZusHogu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "441b3235-156c-4fd0-8125-1bd1e7b70b60"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "tfe = tf.contrib.eager\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob \n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "from IPython import display\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA0OZK7XIE9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44d42809-5002-4227-cedd-ea768892475f"
      },
      "source": [
        "(train_images,_), (test_images,_) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_0TKQQ7IVI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "\n",
        "# Binarization\n",
        "train_images[train_images >= .5] = 1.\n",
        "train_images[train_images < .5] = 0.\n",
        "test_images[test_images >= .5] = 1.\n",
        "test_images[test_images < .5] = 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nINijS2uIt_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUF = 60000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "TEST_BUF = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqGGJOnIwTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdt1gEvNIzO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CVAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.inference_net = tf.keras.Sequential(\n",
        "      [\n",
        "          tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=32, kernel_size=3, strides=(2, 2), activation=tf.nn.relu),\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=64, kernel_size=3, strides=(2, 2), activation=tf.nn.relu),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          # No activation\n",
        "          tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    self.generative_net = tf.keras.Sequential(\n",
        "        [\n",
        "          tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "          tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "          tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=64,\n",
        "              kernel_size=3,\n",
        "              strides=(2, 2),\n",
        "              padding=\"SAME\",\n",
        "              activation=tf.nn.relu),\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=32,\n",
        "              kernel_size=3,\n",
        "              strides=(2, 2),\n",
        "              padding=\"SAME\",\n",
        "              activation=tf.nn.relu),\n",
        "          # No activation\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random_normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random_normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.generative_net(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obfM0b00JS5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "def compute_gradients(model, x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  return tape.gradient(loss, model.trainable_variables), loss\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "def apply_gradients(optimizer, gradients, variables, global_step=None):\n",
        "  optimizer.apply_gradients(zip(gradients, variables), global_step=global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjTBl9AdJakQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "497493df-88ff-4387-93eb-537174da2335"
      },
      "source": [
        "epochs = 100\n",
        "latent_dim = 50\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# keeping the random vector constant for generation (prediction) so\n",
        "# it will be easier to see the improvement.\n",
        "random_vector_for_generation = tf.random_normal(\n",
        "    shape=[num_examples_to_generate, latent_dim])\n",
        "model = CVAE(latent_dim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOzA57LNJjcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model.sample(test_input)\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwx6uPdlJsqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "05bf4733-3a05-4c9c-ac22-c45c4d9a35c8"
      },
      "source": [
        "generate_and_save_images(model, 0, random_vector_for_generation)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  start_time = time.time()\n",
        "  for train_x in train_dataset:\n",
        "    gradients, loss = compute_gradients(model, train_x)\n",
        "    apply_gradients(optimizer, gradients, model.trainable_variables)\n",
        "  end_time = time.time()\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    loss = tfe.metrics.Mean()\n",
        "    for test_x in test_dataset:\n",
        "      loss(compute_loss(model, test_x))\n",
        "    elbo = -loss.result()\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch: {}, Test set ELBO: {}, '\n",
        "          'time elapse for current epoch {}'.format(epoch,\n",
        "                                                    elbo,\n",
        "                                                    end_time - start_time))\n",
        "    generate_and_save_images(\n",
        "        model, epoch, random_vector_for_generation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4, Test set ELBO: -0.0643589092977345, time elapse for current epoch 126.34977555274963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAD7CAYAAACBpZo1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgYCQggYCAghYCAghICBgBAC4H+quXSpWyNHOgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fd0G1EcJwLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRKP9uXDJ25j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_image(epochs)  # Display images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw3rmv0bJ_Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with imageio.get_writer('cvae.gif', mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "    \n",
        "# this is a hack to display the gif inside the notebook\n",
        "os.system('cp cvae.gif cvae.gif.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQFGCNS6KCDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display.Image(filename=\"cvae.gif.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}